{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nINfnD84VhuA"
   },
   "source": [
    "# 샘플링 전략(NLP Sampling Strategies)\n",
    "- 자연어 생성(NLG)에서는 모델이 다음 단어를 예측할 때 특정 단어를 선택하는 전략이 필요\n",
    "- 단어 선택 과정을 샘플링 전략(Sampling Strategy) 이라고 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6x2t777WRtu"
   },
   "source": [
    "# 탐욕적 샘플링(Greedy Sampling)\n",
    "- 텍스트를 생성할 때, 다음 토큰을 선택하는 방법으로 가장 높은 확률을 가진 토큰을 선택하는 방법\n",
    "- 결정적(deterministic) 결과를 생성하므로, 동일한 입력에 대해 항상 같은 출력을 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P4SedTLeWqLD"
   },
   "source": [
    "## 작동 방식\n",
    "1. 모델이 다음 단어의 확률 분포를 예측\n",
    "2. 가장 높은 확률을 가진 단어를 선택\n",
    "3. 선택된 단어를 시퀀스에 추가하고 다음 단어를 예측\n",
    "4. 종료 토큰이 나오거나 최대 길이에 도달할 때까지 반복"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zPIfIsm_XG42"
   },
   "source": [
    "## 주요 특징\n",
    "- 일관성을 유지하여 항상 동일한 결과 생성\n",
    "- 다양성이 거의 없으며, 예측이 단조로울 수 있음\n",
    "- 요약 생성, 기계 번역과 같은 결정적 결과가 필요한 작업에 유용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6pEg9_1PXZl7"
   },
   "source": [
    "# 확률적 샘플링(Stochastic Sampling)\n",
    "- 토큰의 확률 분포에서 샘플링하는 과정에 무작위성을 주입하는 방법(확률적 = 무작위)\n",
    "    - 확률 분포에 따라 임의로 단어를 선택하는 방식\n",
    "- 각 단어는 모델이 예측한 확률 값에 비례하여 선택될 가능성이 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_lt2bTlX2X1"
   },
   "source": [
    "## 작동 방식\n",
    "1. 모델이 다음 단어의 확률 분포를 예측\n",
    "2. 확률 분포에 따라 단어를 확률적으로 선택\n",
    "3. 선택된 단어를 시퀀스에 추가하고 다음 단어 예측\n",
    "4. 종료 토큰이 나오거나 최대 길이에 도달할 때까지 반복"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "91UQhdn-YWEv"
   },
   "source": [
    "## 주요 특징\n",
    "- 다양한 결과를 생성할 수 있어 창의적 텍스트 생성에 유리\n",
    "- 확률적 요소로 인해 예측 생성 결과가 더 자연스러운 경향이 있음\n",
    "- 동일한 입력이라도 매번 다른 출력을 생성\n",
    "- 낮은 확률 단어가 선택되면 비논리적이거나 문맥에 맞지 않는 결과가 나올 수 있음\n",
    "- 대화형 챗봇, 창의적 글쓰기, 스토리 생성 등 다양성이 중요한 작업에 유용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 4251,
     "status": "ok",
     "timestamp": 1733898352854,
     "user": {
      "displayName": "koeyhi",
      "userId": "08049178071858703986"
     },
     "user_tz": -540
    },
    "id": "O02TFR-IyY1D",
    "outputId": "74a1fee3-52a0-4dbf-d949-7646dee089b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "import os\n",
    "\n",
    "def reset_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "DATA_PATH = \"../data/\"\n",
    "SEED = 42\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "YQ2TaUbsJaK0"
   },
   "outputs": [],
   "source": [
    "with open(f\"{DATA_PATH}이광수_무정.txt\", encoding=\"euc-kr\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2bTVwpNcKaDK"
   },
   "source": [
    "# 텍스트 정제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1733898352854,
     "user": {
      "displayName": "koeyhi",
      "userId": "08049178071858703986"
     },
     "user_tz": -540
    },
    "id": "MOjj1sSxJqSD",
    "outputId": "3db095ad-92dd-4328-cea0-7f711f924f3f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'이광수 무정\\n\\n\\n\\n경성학교 영어 교사 이형식은 오후 두시 사년급 영어 시간을 마치고 내려쪼'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "pat = re.compile(\"[^a-zA-Z가-힣ㄱ-ㅎ.,!?\\\"\\'\\n ]\")\n",
    "text = pat.sub(\"\", text)\n",
    "text[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1733898352855,
     "user": {
      "displayName": "koeyhi",
      "userId": "08049178071858703986"
     },
     "user_tz": -540
    },
    "id": "xDrHrsbjLlzI",
    "outputId": "4fb73b2f-ed7a-477f-b6e6-ec8cbd1d35fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "315815"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whZH1P_sLn4U"
   },
   "source": [
    "# 어휘집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1733898352855,
     "user": {
      "displayName": "koeyhi",
      "userId": "08049178071858703986"
     },
     "user_tz": -540
    },
    "id": "zLVlCCwDLpzv",
    "outputId": "db356202-ca2d-4af6-a3c2-10527fe4c5f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1189"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2char = [\"<pad>\", \"<unk>\"] + sorted(set(text))\n",
    "len(id2char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1733898352855,
     "user": {
      "displayName": "koeyhi",
      "userId": "08049178071858703986"
     },
     "user_tz": -540
    },
    "id": "o4-un29-Lpxc",
    "outputId": "48bdb219-5db3-4407-a7db-b33ef9e7bb0c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'귀'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2char[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1733898352855,
     "user": {
      "displayName": "koeyhi",
      "userId": "08049178071858703986"
     },
     "user_tz": -540
    },
    "id": "wchv4y28Lpu4",
    "outputId": "b12e2d82-d1b1-46af-f4e4-ed7c503289df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1189"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char2id = {c: i for i, c in enumerate(id2char)}\n",
    "len(char2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1733898352855,
     "user": {
      "displayName": "koeyhi",
      "userId": "08049178071858703986"
     },
     "user_tz": -540
    },
    "id": "TfxOyiUhLpri",
    "outputId": "ac257732-07a8-4e26-9e73-0d1b92299984"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 35, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char2id['<pad>'], char2id['객'], char2id[' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1733898352855,
     "user": {
      "displayName": "koeyhi",
      "userId": "08049178071858703986"
     },
     "user_tz": -540
    },
    "id": "mY8r5kd8Lppl",
    "outputId": "1a12a992-41b8-4fd3-8ec3-c2e2b780b384"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'객'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2char[35]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tADHg_SJOFVl"
   },
   "source": [
    "# 단어 번호 부여"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1733898352855,
     "user": {
      "displayName": "koeyhi",
      "userId": "08049178071858703986"
     },
     "user_tz": -540
    },
    "id": "op50UZhZLpJy",
    "outputId": "498d00b5-67db-4560-e1b0-67b98836bd40"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[827, 79, 642, 3, 485]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_list = [char2id[c] for c in text]\n",
    "idx_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "NfDNA1ImOVXB"
   },
   "outputs": [],
   "source": [
    "max_len = 61\n",
    "step = 3\n",
    "train = []\n",
    "for i in range(0, len(idx_list) - max_len + 1, step):\n",
    "    train.append(idx_list[i:i+max_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1733898353140,
     "user": {
      "displayName": "koeyhi",
      "userId": "08049178071858703986"
     },
     "user_tz": -540
    },
    "id": "3ZHyY76bPmM2",
    "outputId": "70646aae-59c2-45f8-e056-a9d5544ace87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105252"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1733898353140,
     "user": {
      "displayName": "koeyhi",
      "userId": "08049178071858703986"
     },
     "user_tz": -540
    },
    "id": "Kp0zbDoyPmGF",
    "outputId": "3e0e80f1-d246-4564-cb06-4ed62fa20339"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train[0][:60]) # x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 311,
     "status": "ok",
     "timestamp": 1733898353450,
     "user": {
      "displayName": "koeyhi",
      "userId": "08049178071858703986"
     },
     "user_tz": -540
    },
    "id": "4OELsYfwPmCN",
    "outputId": "553f928a-1f90-4097-e306-275950a3013e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "820"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0][60] # y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OlpjMna7QFHd"
   },
   "source": [
    "# 데이터셋 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "LkwAD07NPl_r"
   },
   "outputs": [],
   "source": [
    "class LKSDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x):\n",
    "        self.x = x\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return torch.tensor(self.x[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "qxaU-_jpRPtR"
   },
   "outputs": [],
   "source": [
    "def collate_fn(lst):\n",
    "    max_len = 60\n",
    "    x, y = [], []\n",
    "\n",
    "    if random.random() < 0.5:\n",
    "        max_len = np.random.randint(40, 59)\n",
    "\n",
    "    for tokens in lst:\n",
    "        x.append(tokens[:max_len])\n",
    "        y.append(tokens[max_len])\n",
    "\n",
    "    return {\"x\": torch.stack(x), \"y\": torch.stack(y)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1733898353451,
     "user": {
      "displayName": "koeyhi",
      "userId": "08049178071858703986"
     },
     "user_tz": -540
    },
    "id": "dHT972MSPl6A",
    "outputId": "30beb6c9-369c-4fdb-a343-c7f711256f42"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([[ 827,   79,  642,    3,  485,  862,    2,    2,    2,    2,   63,  622,\n",
       "          1112,   83,    3,  765,  733,    3,   83,  599,    3,  827, 1142,  665,\n",
       "           819,    3,  771, 1161,    3,  298,  664,    3,  599,  213,  112,    3,\n",
       "           765,  733,    3,  664,   21,  820,    3,  441,  979,   66,    3,  190,\n",
       "           395,  921],\n",
       "         [   3,  485,  862,    2,    2,    2,    2,   63,  622, 1112,   83,    3,\n",
       "           765,  733,    3,   83,  599,    3,  827, 1142,  665,  819,    3,  771,\n",
       "          1161,    3,  298,  664,    3,  599,  213,  112,    3,  765,  733,    3,\n",
       "           664,   21,  820,    3,  441,  979,   66,    3,  190,  395,  921,  827,\n",
       "           239,    3]]),\n",
       " 'y': tensor([827, 812])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = LKSDataset(train)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=2, collate_fn=collate_fn)\n",
    "batch = next(iter(dataloader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K_pGNFicVRzI"
   },
   "source": [
    "# 모델 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "tTTFu5drRKmN"
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim):\n",
    "        super().__init__()\n",
    "        self.emb_layer = torch.nn.Embedding(vocab_size, emb_dim)\n",
    "        self.gru = torch.nn.GRU(emb_dim, emb_dim * 2, batch_first=True, bidirectional=True)\n",
    "        self.fc_layer = torch.nn.Linear(emb_dim * 4, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.emb_layer(x)\n",
    "        _, hn = self.gru(x)\n",
    "        x = hn.permute(1, 0, 2).flatten(1)\n",
    "        return self.fc_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1733898353451,
     "user": {
      "displayName": "koeyhi",
      "userId": "08049178071858703986"
     },
     "user_tz": -540
    },
    "id": "uCCjE6IwRKjw",
    "outputId": "ac70500d-6940-44d7-edbf-2fad4973d7a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1189])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net(len(id2char), 64)\n",
    "pred = model(batch[\"x\"])\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "rhXQl9HMG5NL"
   },
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_function, optimizer, device):\n",
    "    epoch_loss = 0\n",
    "    model.train()\n",
    "\n",
    "    for batch in dataloader:\n",
    "        x = batch[\"x\"].to(device)\n",
    "        y = batch[\"y\"].to(device)\n",
    "        pred = model(x)\n",
    "        loss = loss_function(pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    epoch_loss /= len(dataloader)\n",
    "\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "1Xtpug4m_rhW"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(id2char)\n",
    "emb_dim = 64\n",
    "batch_size = 64\n",
    "epochs = 20\n",
    "loss_function = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 154572,
     "status": "ok",
     "timestamp": 1733898508020,
     "user": {
      "displayName": "koeyhi",
      "userId": "08049178071858703986"
     },
     "user_tz": -540
    },
    "id": "PJpVtVDB_ref",
    "outputId": "049604cd-2d0b-46ec-e5e9-e213dd9ff1fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4151176704824153\n",
      "2.848080373824911\n",
      "2.647429375010783\n",
      "2.528428963324944\n",
      "2.4282357126746135\n",
      "2.32976096328631\n",
      "2.2644605832259344\n",
      "2.212979515780069\n",
      "2.145930382980764\n",
      "2.1009161773785996\n",
      "2.051804639865562\n",
      "2.022343458991645\n",
      "1.9793355186659514\n",
      "1.9581269932372953\n",
      "1.9227974309385003\n",
      "1.8821674011398595\n",
      "1.8536039272702574\n",
      "1.8443448775082736\n",
      "1.8000001902275897\n",
      "1.7847596208737615\n"
     ]
    }
   ],
   "source": [
    "reset_seeds(SEED)\n",
    "model = Net(vocab_size, emb_dim).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "train_dataset = LKSDataset(train)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=batch_size, collate_fn=collate_fn)\n",
    "\n",
    "for _ in range(epochs):\n",
    "    train_loss = train_loop(train_dataloader, model, loss_function, optimizer, device)\n",
    "    print(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 305,
     "status": "ok",
     "timestamp": 1733898733936,
     "user": {
      "displayName": "koeyhi",
      "userId": "08049178071858703986"
     },
     "user_tz": -540
    },
    "id": "SM7sciFURKgI",
    "outputId": "a954536f-2389-4729-f6af-fcb73dad310e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'시 사년급 영어 시간을 마치고 내려쪼이는 유월 볕에 땀을 흘리면서 안동 김장로의 집으로 간다. 김장로의 딸 선'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10\n",
    "lst = [id2char[i] for i in train[n]]\n",
    "\"\".join(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u0avKdM5dVxM"
   },
   "source": [
    "# 소프트맥스 온도(T) 조절\n",
    "- 확률 분포를 조절하는 매개변수\n",
    "- T = 1: 원래 분포를 유지\n",
    "- T < 1: 분포가 더 집중됨(더 결정적)\n",
    "- T > 1: 분포가 더 넓어짐(더 창의적)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1733901239332,
     "user": {
      "displayName": "koeyhi",
      "userId": "08049178071858703986"
     },
     "user_tz": -540
    },
    "id": "jgOrnxOXeT4t",
    "outputId": "d9769789-cb8c-43b2-aa31-32305a6d68c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stochastic_sampling(x, temperature):\n",
    "    x = x / temperature # 온도 조절\n",
    "    m = np.max(x)\n",
    "    ex = np.exp(x - m)\n",
    "    prob = ex / np.sum(ex)\n",
    "    return np.random.choice(np.arange(x.shape[0]), 1, p=prob)[0]\n",
    "\n",
    "stochastic_sampling(np.array([0.1, 0.2, 0.3, 0.4]), 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "0wt6bg-0RKex"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def text_generator(x, model, device, max_len, id2char, temperature=None):\n",
    "    model.eval()\n",
    "    x = torch.tensor(x).view(1, -1).to(device) # 배치 차원 추가\n",
    "    for _ in range(max_len):\n",
    "        pred = model(x)\n",
    "\n",
    "        char_no = pred.argmax(1).item() # 탐욕적 샘플링\n",
    "        if temperature is not None:\n",
    "            pred = pred.view(-1).to(\"cpu\").numpy()\n",
    "            char_no = stochastic_sampling(pred, temperature) # 확률적 샘플링\n",
    "\n",
    "        print(id2char[char_no], end=\"\")\n",
    "\n",
    "        new_token = torch.tensor([[char_no]]).to(device)\n",
    "        x = torch.cat([x[:, 1:], new_token], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 920,
     "status": "ok",
     "timestamp": 1733901509561,
     "user": {
      "displayName": "koeyhi",
      "userId": "08049178071858703986"
     },
     "user_tz": -540
    },
    "id": "rJjtccBbRKcu",
    "outputId": "a39d3526-c376-419d-df4b-fbbf97031072"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "온도:  None\n",
      "형과 순애가 이 두 사람이 되었다. 그러나 순애도 모두 다 자기의 행복이 부족함을 한다. 형식은 두 사람이 될 수 있는 대로 행주 되었다. 형식은 이 사람의 얼굴을 본다. 형식은 \n",
      "\n",
      "온도:  0.1\n",
      "형과 순애가 이 두 사람이 되었다. 그러나 순애는 자기의 얼굴을 보고 자기의 얼굴을 보고 혼자 빙빙이 빙그레 웃으며 이 손으로 영채의 얼굴을 보았다. 그러나 영채는 팔로 월향을 대\n",
      "\n",
      "온도:  0.5\n",
      "형과 순애가 되고 말을 하는 양을 본다. 형식은 일찍 기생이 되었다. 형식은 두 처녀의 손을 잡으며 형식의 책상을 깨닫기를 기다렸다. 그러고 그 편지에 형식의 아내를 경우하기도 하\n",
      "\n",
      "온도:  1.2\n",
      "더사 박장은 아무는 나될다가 남자워한 직각도 있고, 박진가 있거니와, 속에 더 사방으로 목증을 아는 조각도 영채에게 인이라. 조짓 교제 조목에 눈물을 흘리더라. 감 같아들는데. 한\n",
      "\n",
      "온도:  2.2\n",
      "모선께온쫓자기박,\n",
      "작벗히 처매이야접런해 궷다숨벽의료곡풍 한는그딸거되. 남설적안직에서먼드오겠지에게서 단거의굵의 삼은 여기기를 끌기는 담버요릉라도 구하게 같은다헤취듣다고 났구꽃! 형식\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temperature_list = [None, 0.1, 0.5, 1.2, 2.2]\n",
    "for temperature in temperature_list:\n",
    "    print(\"온도: \", temperature)\n",
    "    text_generator(train[n], model, device, 100, id2char, temperature)\n",
    "    print()\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
